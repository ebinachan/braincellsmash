input {
  udp {
    port => "5145"
    type => "syslog-ne"
  }
}

#
# FILTER - NE log format
#
# Configuration:
# info-center source default channel 0 log state off trap state off
# info-center source default channel 4 log level debugging
# info-center loghost 10.10.10.10 source-ip 1.1.1.1 port 5145 local-time
# info-center timestamp log format-date precision-time millisecond
# info-center timestamp trap format-date precision-time millisecond

filter {
  # NOTE: The frontend logstash servers set the type of incoming messages.
  if [type] == "syslog-ne" {
    # The switches are sending the same message to all syslog servers for redundancy, this allows us to
    ## only store the message in elasticsearch once by generating a hash of the message and using that as
    ## the document_id.
    fingerprint {
      source              => [ "message" ]
      method              => "SHA1"
      key                 => "Some super secret passphrase for uniqueness."
      concatenate_sources => true
    }

    # Parse the log entry into sections.
    grok {
      # There are a couple of custom patterns associated with this filter.
      # patterns_dir => [ "/usr/share/logstash/patterns" ]

      match => [
        # NE Logs
        "message", "<%{POSINT:pri}>%{TIMESTAMP_ISO8601:time}%{SPACE}%{DATA:hostname}%{SPACE}%%%{DATA:facility}/%{POSINT:lvl}/%{DATA:facility_mnemonic}:%{DATA:cid};%{GREEDYDATA:message}"
      ]

      overwrite => [ "message" ]
      add_tag => [ "ne" ]
      remove_field => [ "pri", "@version" ]
    }
  }

    # Add the log level name instead of just a number.
    mutate {
      gsub => [
        "lvl", "0", "0 emerg",
        "lvl", "1", "1 alert",
        "lvl", "2", "2 critical",
        "lvl", "3", "3 error",
        "lvl", "4", "4 warning",
        "lvl", "5", "5 notice",
        "lvl", "6", "6 info",
        "lvl", "7", "7 debug"
      ]
    }

#  } # if
} # filter



output {
  elasticsearch {
    hosts => "127.0.0.1:9200"
    index => "syslog"
  }
}
