input {
    udp {
        port => "5140"
        type => "transparent"
    }
    udp {
      port => "5141"
      type => "syslog-cisco-xr"
    }
    udp {
        port => "5145"
        type => "syslog-ne"
    }
}


filter {
    # NOTE: The frontend logstash servers set the type of incoming messages.
    # Routers are sending the same message to all syslog servers for redundancy, this allows us to
    ## only store the message in elasticsearch once by generating a hash of the message and using that as
    ## the document_id.
    fingerprint {
        source              => [ "message" ]
        method              => "SHA1"
        key                 => "Some super secret passphrase for uniqueness."
        concatenate_sources => true
    }

    if [type] == "syslog-cisco-xr" {
    #
        # FILTER - Try to parse the cisco log format
        #
        # Configuration:
        # logging format rfc5424/bsd
        # logging 10.10.10.10 vrf default severity info port 5141
        # logging source-interface Loopback0
        # logging hostnameprefix __DISCOBEAR
        # logging suppress duplicates

        # Parse the log entry into sections.  Cisco doesn't use a consistent log format, unfortunately.
        grok {
          # There are a couple of custom patterns associated with this filter.
          # patterns_dir => [ "/usr/share/logstash/patterns" ]
    
          match => [
            # IOS-XR BSD Log Format
            # "message", "<%{POSINT:pri}>%{DATA:log_date}__%{DATA:hostname} %{DATA:slot}:%{DATA:job_id}: %%{DATA:facility}-%{INT:lvl}-%{DATA:facility_mnemonic} : %{GREEDYDATA:message}",
            # IOS-XR RFC5424 Logs
            "message", "<%{POSINT:pri}>%{POSINT:version}%{SPACE}%{DATA:log_date}%{SPACE}__%{DATA:hostname} %{DATA:extjob}: %{DATA:slot}:%{DATA:job_id}: %%{DATA:facility}-%{INT:lvl}-%{DATA:facility_mnemonic} : %{GREEDYDATA:message}"
          ]
    
          overwrite => [ "message" ]
          add_tag => [ "cisco_xr" ]
          remove_field => [ "pri", "@version" ]
        } # grok
    } # if type


    if [type] == "syslog-ne" {
        grok {
            # There are a couple of custom patterns associated with this filter.
            # patterns_dir => [ "/usr/share/logstash/patterns" ]
      
            match => [
              # NE Logs
              "message", "<%{POSINT:pri}>%{TIMESTAMP_ISO8601:log_date}%{SPACE}%{DATA:hostname}%{SPACE}%%%{DATA:facility}/%{POSINT:lvl}/%{DATA:facility_mnemonic}:%{DATA:cid};%{GREEDYDATA:message}"
            ]
      
            overwrite => [ "message" ]
            add_tag => [ "ne" ]
            remove_field => [ "pri", "@version" ]
        } # grok
    } # if type

    # If we made it here, the grok was sucessful
    if "cisco_xr" in [tags] {
        date {
            match => [
                "log_date",

                # IOS
                "MMM dd HH:mm:ss.SSS ZZZ",
                "MMM dd HH:mm:ss ZZZ",
                "MMM dd HH:mm:ss.SSS",
        
                # Nexus
                "YYYY MMM dd HH:mm:ss.SSS ZZZ",
                "YYYY MMM dd HH:mm:ss ZZZ",
                "YYYY MMM dd HH:mm:ss.SSS",
        
                # Hail Mary
                "ISO8601"
            ]
        } # date
    } # if tags

    if "ne" in [tags] {
        date {  
            match => [  
                "log_date",  
                "ISO8601"  
            ]
        } # date
    } # if tags

    # Add the log level name instead of just a number.
    mutate {
        gsub => [
            "lvl", "0", "0 emerg",
            "lvl", "1", "1 alert",
            "lvl", "2", "2 critical",
            "lvl", "3", "3 error",
            "lvl", "4", "4 warning",
            "lvl", "5", "5 notice",
            "lvl", "6", "6 info",
            "lvl", "7", "7 debug"
        ]
    } # mutate
} # filter


output { 
    elasticsearch {
        hosts => "127.0.0.1:9200"
        index => "syslog"
    }
}

